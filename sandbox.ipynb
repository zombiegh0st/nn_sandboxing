{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.         0.50196078 0.        ]\n",
      "  [0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         1.        ]\n",
      "  [1.         1.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# Ein 3D-Array, das ein 2x2 Bild mit 3 Farbkanälen (RGB) darstellt\n",
    "array_3d = np.array([[[255, 128, 0], [0, 255, 0]],\n",
    "                     [[0, 0, 255], [255, 255, 255]]])\n",
    "\n",
    "# Division durch 255\n",
    "normalized_array_3d = array_3d / 255.0\n",
    "print(normalized_array_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      "[[[[211  39 138]\n",
      "   [ 31 178  85]]\n",
      "\n",
      "  [[216 102 198]\n",
      "   [125 118 123]]]\n",
      "\n",
      "\n",
      " [[[234  78  33]\n",
      "   [  5 214 254]]\n",
      "\n",
      "  [[ 67  11  39]\n",
      "   [ 18 133  83]]]]\n",
      "\n",
      "Normalisiertes Array:\n",
      "[[[[0.82745098 0.15294118 0.54117647]\n",
      "   [0.12156863 0.69803922 0.33333333]]\n",
      "\n",
      "  [[0.84705882 0.4        0.77647059]\n",
      "   [0.49019608 0.4627451  0.48235294]]]\n",
      "\n",
      "\n",
      " [[[0.91764706 0.30588235 0.12941176]\n",
      "   [0.01960784 0.83921569 0.99607843]]\n",
      "\n",
      "  [[0.2627451  0.04313725 0.15294118]\n",
      "   [0.07058824 0.52156863 0.3254902 ]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ein 4-dimensionales Array erstellen (z.B. ein Batch von Bildern in einem RGB-Format)\n",
    "array_4d = np.random.randint(0, 256, (2, 2, 2, 3))\n",
    "\n",
    "print(\"Original Array:\")\n",
    "print(array_4d)\n",
    "\n",
    "# Division durch 255\n",
    "normalized_array_4d = array_4d / 255.0\n",
    "\n",
    "print(\"\\nNormalisiertes Array:\")\n",
    "print(normalized_array_4d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Eingabedaten: [[1. 2. 3.]]\n",
      "Ausgabe der Dense-Schicht: [[0.2665392]]\n",
      "Gewichte (Weights): [[-0.16676378]\n",
      " [ 0.23313022]\n",
      " [-0.04431915]]\n",
      "Bias (Biases): [0.1]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Eingabedaten: [[1. 2. 3.]]\n",
      "Ausgabe der Dense-Schicht: [[0.2665392]]\n",
      "Gewichte (Weights): [[-0.16676378]\n",
      " [ 0.23313022]\n",
      " [-0.04431915]]\n",
      "Bias (Biases): [0.1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Erstellen einer Dense-Schicht mit 1 Neuron und ReLU-Aktivierung\n",
    "dense_layer = tf.keras.layers.Dense(1, activation='relu', input_shape=(3,),bias_initializer=Constant(0.1))\n",
    "# dense_layer = tf.keras.layers.Dense(1, activation='relu', input_shape=(3,),bias_regularizer=l2(1))\n",
    "\n",
    "# Erstellen eines Modells, das diese Schicht enthält\n",
    "model = tf.keras.models.Sequential([dense_layer])\n",
    "\n",
    "# Initialisieren des Modells mit zufälligen Gewichten\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Eingabedaten: ein 1x3 Array\n",
    "input_data = np.array([[1.0, 2.0, 3.0]])\n",
    "\n",
    "# Voraussage durchführen\n",
    "output = model.predict(input_data)\n",
    "\n",
    "# Ausgabe der Resultate\n",
    "print(\"Eingabedaten:\", input_data)\n",
    "print(\"Ausgabe der Dense-Schicht:\", output)\n",
    "print(\"Gewichte (Weights):\", dense_layer.get_weights()[0])\n",
    "print(\"Bias (Biases):\", dense_layer.get_weights()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999 1.998 2.997]\n"
     ]
    }
   ],
   "source": [
    "# sdg funktion\n",
    "def sgd(weights, gradients, learning_rate):\n",
    "    updated_weights = weights - learning_rate * gradients\n",
    "    return updated_weights\n",
    "\n",
    "result = sgd(np.array([1, 2, 3]), np.array([0.1, 0.2, 0.3]), 0.01)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output der Dense-Schicht: [1.3 0.7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def dense_layer(inputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Führt eine Berechnung in einer Dense-Schicht durch.\n",
    "    \n",
    "    Args:\n",
    "    inputs (numpy.array): Eingabewerte zur Schicht.\n",
    "    weights (numpy.array): Gewichtsmatrix der Schicht.\n",
    "    bias (numpy.array): Bias-Vektor der Schicht.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.array: Die aktivierten Ausgaben der Schicht.\n",
    "    \"\"\"\n",
    "    z = np.dot(weights, inputs) + bias\n",
    "    a = relu(z)\n",
    "    return a\n",
    "\n",
    "# Beispiel für Eingabewerte\n",
    "inputs = np.array([1.5, 2.0, 3.0])\n",
    "\n",
    "# Beispielgewichte und Bias für eine Schicht mit 3 Eingängen und 2 Ausgängen\n",
    "weights = np.array([\n",
    "    [0.2, -0.3, 0.5],\n",
    "    [-0.6, 0.7, 0.1]\n",
    "])\n",
    "bias = np.array([0.1, -0.1])\n",
    "\n",
    "# Ausführen der Dense-Schicht\n",
    "output = dense_layer(inputs, weights, bias)\n",
    "print(\"Output der Dense-Schicht:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: [3 9 5]\n",
      "Ergebnis von DOT: [0.40000000000000036, 5.0]\n",
      "Ergebnis inkl. Bias: [0.5000000000000003, 4.9]  | Bias:  [0.1, -0.1]\n",
      "Output der Dense-Schicht (Relu): [0.5000000000000003, 4.9]\n"
     ]
    }
   ],
   "source": [
    "def manuelle_dot(matrix, vektor):\n",
    "    \"\"\"\n",
    "    Multipliziert eine Matrix mit einem Vektor und gibt das Ergebnis zurück.\n",
    "\n",
    "    Args:\n",
    "    matrix (list of list of float): Die Matrix der Gewichte.\n",
    "    vektor (list of float): Der Vektor der Eingänge.\n",
    "\n",
    "    Returns:\n",
    "    list of float: Das Ergebnis der Matrix-Vektor-Multiplikation.\n",
    "    \"\"\"\n",
    "    ergebnis = []\n",
    "    # Gehe durch jede Zeile der Matrix\n",
    "    for zeile in matrix:\n",
    "        summe = 0\n",
    "        # Multipliziere jedes Element der Zeile mit dem entsprechenden Element des Vektors\n",
    "        for i in range(len(vektor)):\n",
    "            summe += zeile[i] * vektor[i]\n",
    "        # Füge die summierte Zahl zum Ergebnisvektor hinzu\n",
    "        ergebnis.append(summe)\n",
    "    return ergebnis\n",
    "\n",
    "# Beispiel für Eingabewerte\n",
    "# inputs = [1.5, 2.0, 3.0]\n",
    "# randomized inpunts\n",
    "inputs = np.random.randint(0, 10, 3)\n",
    "print(\"inputs:\", inputs)\n",
    "\n",
    "# Beispielgewichte und Bias für eine Schicht mit 3 Eingängen und 2 Ausgängen\n",
    "weights = [\n",
    "    [0.2, -0.3, 0.5],\n",
    "    [-0.6, 0.7, 0.1]\n",
    "]\n",
    "bias = [0.1, -0.1]\n",
    "\n",
    "# Ausführen der manuellen Matrix-Vektor-Multiplikation\n",
    "z = manuelle_dot(weights, inputs)\n",
    "print(\"Ergebnis von DOT:\", z)\n",
    "\n",
    "# Hinzufügen des Bias zu jedem Element des Ergebnisvektors\n",
    "z = [z[i] + bias[i] for i in range(len(bias))]\n",
    "print(\"Ergebnis inkl. Bias:\", z, \" | Bias: \",bias)\n",
    "\n",
    "\n",
    "# Anwenden der ReLU Funktion\n",
    "output = [max(0, x) for x in z]\n",
    "\n",
    "print(\"Output der Dense-Schicht (Relu):\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_shifted: [1.         0.36787944 0.14956862]\n",
      "Softmax Wahrscheinlichkeiten: [0.65900114 0.24243297 0.09856589]\n",
      "Summe der Wahrscheinlichkeiten: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(logits):\n",
    "    # Verhindert Überlauf\n",
    "    exp_shifted = np.exp(logits - np.max(logits))\n",
    "    # exp_shifted = np.exp(logits )\n",
    "    print(\"exp_shifted:\", exp_shifted)\n",
    "    # Berechnung der Softmax-Wahrscheinlichkeiten\n",
    "    probabilities = exp_shifted / np.sum(exp_shifted)\n",
    "    return probabilities\n",
    "\n",
    "# Beispiel für Logits\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "\n",
    "# Anwendung der Softmax-Funktion\n",
    "probabilities = softmax(logits)\n",
    "print(\"Softmax Wahrscheinlichkeiten:\", probabilities)\n",
    "print(\"Summe der Wahrscheinlichkeiten:\", np.sum(probabilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a.denisov\\Documents\\Dev\\sandbox\\nn_stocks\\.env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 'mse' für Regression, 'categorical_crossentropy' für Klassifikation\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Modell trainieren\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(data, \u001b[43mlabels\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Angenommen, data ist dein vorbereiteter Datensatz, der in passender Form vorliegt\n",
    "# Beispiel: data = np.random.rand(1000, 10, 6) # 1000 Samples, 10 Zeitpunkte, 6 Features (5 numerische Werte + 1 Zeitstempel)\n",
    "\n",
    "# Modelldefinition\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(10, 6)),  # 10 Zeitpunkte, 6 Features\n",
    "    LSTM(50),\n",
    "    Dense(1)  # oder Dense(n) für n Klassen bei Klassifizierungsproblemen\n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='mse')  # 'mse' für Regression, 'categorical_crossentropy' für Klassifikation\n",
    "\n",
    "# Modell trainieren\n",
    "history = model.fit(data, labels, epochs=20, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Angenommen, data ist dein vorbereiteter Datensatz, der in passender Form vorliegt\n",
    "data = np.random.rand(1000, 10, 6) # 1000 Samples, 10 Zeitpunkte, 6 Features (5 numerische Werte + 1 Zeitstempel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFChartError('%ticker%: 1m data not available for startTime=1687953271 and endTime=1719489271. Only 7 days worth of 1m granularity data are allowed to be fetched per request.')\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFChartError('%ticker%: 1m data not available for startTime=1687953271 and endTime=1719489271. Only 7 days worth of 1m granularity data are allowed to be fetched per request.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data from yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# get minute data for the last 5 days\n",
    "ticker = 'AAPL'\n",
    "period = '1y'\n",
    "interval = '1m'\n",
    "df = yf.download(ticker, period=period, interval=interval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
